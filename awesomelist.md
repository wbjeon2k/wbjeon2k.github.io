---
layout: article
title: "Awesome List of Continual Learning"
permalink: /awesomelist.html
<!--author: wbjeon2k-->
---
### Awesome Continual Learning

Github의 [xialeiliu/Awesome-Incremental-Learning](https://github.com/xialeiliu/Awesome-Incremental-Learning) 의 reading list를 퍼왔다.  

AI 분야에서 1년간 발표되는 모든 논문을 전부 다 읽는것은 불가능하다.  
하지만 많이 읽을수록 연구 동향을 파악하고 주제 선정을 하는데 도움이 되는것은 의심의 여지가 없다.  

신년에는 다들 지킬 수 없는 목표를 하나씩 세우는 것 처럼,  
이번 신년에는 3월 개강 전 까지 아래에 소개된 모든 논문들을 읽어보는 것을 목표로 정했다!  

읽은 것은 블로그 포스트로 정리하면서, 하나씩 ~~취소선으로~~ 지워나가며 꾸준히 업데이트를 할 예정이다.  
이미 읽어 봤거나 들어본 논문보다 처음 보는 논문이 많은 것에 그 동안 논문 읽기가 소홀했음을 알게되었다.  

disclaimer : 다른 분야에서 두각을 나타내는 박재우 군이 자기 분야에서 출간 된 한 해 논문을 전부 읽었다는 얘기에 영감을 받았다.  

정리하는 양식은 다음과 같다.

```text
## Name of the paper
### Quick Look
- **Authors & Affiliation**: [Authors][Affiliations]
- **Link**: [Paper link]
- **Comments**: [e.g. Published at X / arXiv paper / in review.]
- **TLDR**: [One or at most two line summary]
- **Relevance**: [Score between 1 and 5, stating how relevant this paper is to your work. Usually filled in at the end.]
### Research Topic
- **Category** (General):
- **Category** (Specific):
### Paper Summary (What)
[Summary of the paper - a few sentences with bullet points. What did they do?]
```


### 2022

- FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning (**WACV2023**)[[paper]( https://arxiv.org/abs/2211.13131)]
- Balanced softmax cross-entropy for incremental learning with and without memory (**CVIU**)[[paper](https://www.sciencedirect.com/science/article/pii/S1077314222001606)]
- Online Continual Learning through Mutual Information Maximization (**ICML2022**)[[paper](https://proceedings.mlr.press/v162/guo22g/guo22g.pdf)]
- Improving Task-free Continual Learning by Distributionally Robust Memory Evolution (**ICML2022**)[[paper](https://proceedings.mlr.press/v162/wang22v/wang22v.pdf)]
- Forget-free Continual Learning with Winning Subnetworks (**ICML2022**)[[paper](https://proceedings.mlr.press/v162/kang22b/kang22b.pdf)]
- NISPA: Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks (**ICML2022**)[[paper](https://proceedings.mlr.press/v162/gurbuz22a/gurbuz22a.pdf)]
- Continual Learning via Sequential Function-Space Variational Inference (**ICML2022**)[[paper](https://proceedings.mlr.press/v162/rudner22a/rudner22a.pdf)]
- On Solving Class Incremental Learning in Continual Learning (**NeurIPS2022**)
- A Theoretical Study on Solving Continual Learning (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2211.02633)] [[code](https://github.com/k-gyuhak/WPTP)]
- Beyond Not-Forgetting: Continual Learning with Backward Knowledge Transfer (**NeurIPS2022**)
- Memory Efficient Continual Learning with Transformers (**NeurIPS2022**) [[paper](https://assets.amazon.science/44/6c/6d3f91ca4aa7a18149d30fa2c8a4/memory-efficient-continual-learning-with-transformers.pdf)]
- Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2210.04524)] [[code](https://github.com/zoilsen/clom)]
- Disentangling Transfer in Continual Reinforcement Learning (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2209.13900)]
- Task-Free Continual Learning via Online Discrepancy Distance Learning (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2210.06579)]
- A simple but strong baseline for online continual learning: Repeated Augmented Rehearsal (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2209.13917)]
- S-Prompts Learning with Pre-trained Transformers: An Occam’s Razor for Domain Incremental Learning (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2207.12819)]
- Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting (**NeurIPS2022**) [[paper](https://arxiv.org/abs/1905.10696)]
- Few-Shot Continual Active Learning by a Robot (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2210.04137)]
- Continual learning: a feature extraction formalization, an efficient algorithm, and fundamental obstructions(**NeurIPS2022**) [[paper](https://arxiv.org/abs/2203.14383)]
- SparCL: Sparse Continual Learning on the Edge(**NeurIPS2022**) [[paper](https://arxiv.org/abs/2209.09476)]
- CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks (**NeurIPS2022**) [[paper](https://openreview.net/forum?id=FhqzyGoTSH)] [[code](https://github.com/GLAMOR-USC/CLiMB)]
- Continual Learning In Environments With Polynomial Mixing Times (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2112.07066)] [[code](https://github.com/sharathraparthy/polynomial-mixing-times)]
- Exploring Example Influence in Continual Learning (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2209.12241)] [[code](https://github.com/sssunqing/example_influence_cl)]
- ALIFE: Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2210.06816)]
- On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2210.06443)] [[code](https://github.com/aimagelab/lider)]
- On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting (**NeurIPS2022**)[[paper](https://arxiv.org/abs/2206.00761)]
- CGLB: Benchmark Tasks for Continual Graph Learning (**NeurIPS2022**)[[paper](https://openreview.net/forum?id=5wNiiIDynDF)] [[code](https://github.com/QueuQ/CGLB)]
- How Well Do Unsupervised Learning Algorithms Model Human Real-time and Life-long Learning? (**NeurIPS2022**)[[paper](https://openreview.net/forum?id=c0l2YolqD2T)]
- CoSCL: Cooperation of Small Continual Learners is Stronger than a Big One (**ECCV2022**)[[paper](https://arxiv.org/abs/2207.06543)] [[code](https://github.com/lywang3081/CoSCL)]
- Generative Negative Text Replay for Continual Vision-Language Pretraining (**ECCV2022**) [[paper](https://arxiv.org/abs/2210.17322)]
- DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2204.04799)] [[code](https://github.com/google-research/l2p)]
- The Challenges of Continuous Self-Supervised Learning (**ECCV2022**)[[paper](https://arxiv.org/abs/2203.12710)]
- Helpful or Harmful: Inter-Task Association in Continual Learning (**ECCV2022**)[[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136710518.pdf)]
- incDFM: Incremental Deep Feature Modeling for Continual Novelty Detection (**ECCV2022**)[[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850581.pdf)]
- S3C: Self-Supervised Stochastic Classifiers for Few-Shot Class-Incremental Learning (**ECCV2022**)[[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850427.pdf)]
- Online Task-free Continual Learning with Dynamic Sparse Distributed Memory (**ECCV2022**)[[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850721.pdf)][[code](https://github.com/Julien-pour/Dynamic-Sparse-Distributed-Memory)]
- Balancing between Forgetting and Acquisition in Incremental Subpopulation Learning (**ECCV2022**)[[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136860354.pdf)]
- Class-Incremental Learning with Cross-Space Clustering and Controlled Transfer (**ECCV2022**) [[paper](https://arxiv.org/abs/2208.03767)] [[code](https://github.com/ashok-arjun/CSCCT)]
- FOSTER: Feature Boosting and Compression for Class-Incremental Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2204.04662)] [[code](https://github.com/G-U-N/ECCV22-FOSTER)]
- Meta-Learning with Less Forgetting on Large-Scale Non-Stationary Task Distributions (**ECCV2022**) [[paper](https://arxiv.org/abs/2209.01501)]
- R-DFCIL: Relation-Guided Representation Learning for Data-Free Class Incremental Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2203.13104)] [[code](https://github.com/jianzhangcs/r-dfcil)]
- DLCFT: Deep Linear Continual Fine-Tuning for General Incremental Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2208.08112)]
- Learning with Recoverable Forgetting (**ECCV2022**) [[paper](https://arxiv.org/abs/2207.08224)]
- Prototype-Guided Continual Adaptation for Class-Incremental Unsupervised Domain Adaptation (**ECCV2022**) [[paper](https://arxiv.org/abs/2207.10856)] [[code](https://github.com/hongbin98/proca)]
- Balancing Stability and Plasticity through Advanced Null Space in Continual Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2207.12061)]
- Long-Tailed Class Incremental Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2210.00266)]
- Anti-Retroactive Interference for Lifelong Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2208.12967)]
- Novel Class Discovery without Forgetting (**ECCV2022**) [[paper](https://arxiv.org/abs/2207.10659)]
- Class-incremental Novel Class Discovery (**ECCV2022**) [[paper](https://arxiv.org/abs/2207.08605)]
- Few-Shot Class Incremental Learning From an Open-Set Perspective(**ECCV2022**)[[paper](https://arxiv.org/pdf/2208.00147.pdf)]
- Incremental Task Learning with Incremental Rank Updates(**ECCV2022**)[[paper](https://arxiv.org/pdf/2207.09074.pdf)]
- Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free Replay(**ECCV2022**)[[paper](https://arxiv.org/pdf/2207.11213.pdf)]
- Online Continual Learning with Contrastive Vision Transformer (**ECCV2022**)[[paper](https://arxiv.org/pdf/2207.13516.pdf)]
- Transfer without Forgetting (**ECCV2022**) [[paper](https://arxiv.org/abs/2206.00388)][[code](https://github.com/mbosc/twf)]

- Continual Training of Language Models for Few-Shot Learning (**EMNLP2022**) [[paper](https://arxiv.org/abs/2210.05549)] [[code](https://github.com/UIC-Liu-Lab/CPT)]
- Uncertainty-aware Contrastive Distillation for Incremental Semantic Segmentation (**TPAMI2022**) [[paper](https://arxiv.org/abs/2203.14098)]
- MgSvF: Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning (**TPAMI2022**) [[paper](https://ieeexplore.ieee.org/abstract/document/9645290)]
- Class-Incremental Continual Learning into the eXtended DER-verse (**TPAMI2022**) [[paper](https://arxiv.org/abs/2201.00766)] [[code](https://github.com/aimagelab/mammoth)]
- Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks (**TPAMI2022**) [[paper](https://arxiv.org/abs/2203.17030)] [[code](https://github.com/zhoudw-zdw/TPAMI-Limit)]
- Continual Semi-Supervised Learning through Contrastive Interpolation Consistency (**PRL2022**) [[paper](https://arxiv.org/abs/2108.06552)][[code](https://github.com/aimagelab/CSSL)]
- GCR: Gradient Coreset Based Replay Buffer Selection for Continual Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2111.11210)]
- Learning Bayesian Sparse Networks With Full Experience Replay for Continual Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2202.10203)]
- Continual Learning With Lifelong Vision Transformer (**CVPR2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Continual_Learning_With_Lifelong_Vision_Transformer_CVPR_2022_paper.pdf)]
- Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector (**CVPR2022**) [[paper](https://arxiv.org/abs/2110.07905)]
- Doodle It Yourself: Class Incremental Learning by Drawing a Few Sketches (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.14843)]
- Continual Learning for Visual Search with Backward Consistent Feature Embedding (**CVPR2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Continual_Learning_for_Visual_Search_With_Backward_Consistent_Feature_Embedding_CVPR_2022_paper.pdf)]
- Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.15355)]
- Not Just Selection, but Exploration: Online Class-Incremental Continual Learning via Dual View Consistency (**CVPR2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Not_Just_Selection_but_Exploration_Online_Class-Incremental_Continual_Learning_via_CVPR_2022_paper.pdf)]
- Bring Evanescent Representations to Life in Lifelong Class Incremental Learning (**CVPR2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Toldo_Bring_Evanescent_Representations_to_Life_in_Lifelong_Class_Incremental_Learning_CVPR_2022_paper.pdf)]
- Lifelong Graph Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2009.00647)]
- Lifelong Unsupervised Domain Adaptive Person Re-identification with Coordinated Anti-forgetting and Adaptation (**CVPR2022**) [[paper](https://arxiv.org/abs/2112.06632)]
- vCLIMB: A Novel Video Class Incremental Learning Benchmark (**CVPR2022**) [[paper](https://arxiv.org/abs/2201.09381)]
- Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation(**CVPR2022**) [[paper](https://arxiv.org/abs/2204.00895)]
- Few-Shot Incremental Learning for Label-to-Image Translation (**CVPR2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Few-Shot_Incremental_Learning_for_Label-to-Image_Translation_CVPR_2022_paper.pdf)]
- MetaFSCIL: A Meta-Learning Approach for Few-Shot Class Incremental Learning (**CVPR2022**) [[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Chi_MetaFSCIL_A_Meta-Learning_Approach_for_Few-Shot_Class_Incremental_Learning_CVPR_2022_paper.pdf)]
- Incremental Learning in Semantic Segmentation from Image Labels (**CVPR2022**) [[paper](https://arxiv.org/abs/2112.01882)]
- Self-Supervised Models are Continual Learners (**CVPR2022**) [[paper](https://arxiv.org/abs/2112.04215)] [[code](https://github.com/DonkeyShot21/cassle)]
- Learning to Imagine: Diversify Memory for Incremental Learning using Unlabeled Data (**CVPR2022**) [[paper](https://arxiv.org/abs/2204.08932)]
- General Incremental Learning with Domain-aware Categorical Representations (**CVPR2022**) [[paper](https://arxiv.org/abs/2204.04078)]
- Constrained Few-shot Class-incremental Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.16588)]
- Overcoming Catastrophic Forgetting in Incremental Object Detectionvia Elastic Response Distillation (**CVPR2022**) [[paper](https://arxiv.org/abs/2204.02136)]
- Class-Incremental Learning with Strong Pre-trained Models (**CVPR2022**) [[paper](https://arxiv.org/abs/2204.03634)]
- Energy-based Latent Aligner for Incremental Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.14952)] [[code](https://github.com/JosephKJ/ELI)]
- Meta-attention for ViT-backed Continual Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.11684)] [[code](https://github.com/zju-vipa/MEAT-TIL)]
- Learning to Prompt for Continual Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2112.08654)] [[code](https://github.com/google-research/l2p)]
- On Generalizing Beyond Domains in Cross-Domain Continual Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.03970)]
- Probing Representation Forgetting in Supervised and Unsupervised Continual Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.13381)]
- Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.00867)] [[code](https://github.com/DQiaole/ZITS_inpainting)]
- Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2112.04731)] [[code](https://github.com/Yujun-Shi/CwD)]
- Forward Compatible Few-Shot Class-Incremental Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.06953)] [[code](https://github.com/zhoudw-zdw/CVPR22-Fact)]
- Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.06359)]
- DyTox: Transformers for Continual Learning with DYnamic TOken eXpansion (**CVPR2022**) [[paper](https://arxiv.org/abs/2111.11326)]
- Federated Class-Incremental Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.11473)] [[code](https://github.com/conditionWang/FCIL)]
- Representation Compensation Networks for Continual Semantic Segmentation (**CVPR2022**) [[paper](https://arxiv.org/abs/2203.05402)]
- A Multi-Head Model for Continual Learning via Out-of-Distribution Replay (**CoLLAs2022**) [[paper](https://arxiv.org/abs/2208.09734)] [[code](https://github.com/k-gyuhak/MORE)]
- Continual Attentive Fusion for Incremental Learning in Semantic Segmentation (**TMM2022**) [[paper](https://arxiv.org/abs/2202.00432)]
- Self-training for class-incremental semantic segmentation (**TNNLS2022**) [[paper](https://arxiv.org/abs/2012.03362)]
- Effects of Auxiliary Knowledge on Continual Learning (**ICPR2022**) [[paper](https://arxiv.org/abs/2206.02577)]
- Continual Sequence Generation with Adaptive Compositional Modules (**ACL2022**) [[paper](https://arxiv.org/pdf/2203.10652.pdf)]
- Learngene: From Open-World to Your Learning Task (**AAAI2022**) [[paper](https://arxiv.org/pdf/2106.06788.pdf)] [[code](https://github.com/BruceQFWang/learngene)]

- Rethinking the Representational Continuity: Towards Unsupervised Continual Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=9Hrka5PA7LW)]
- Continual Learning with Filter Atom Swapping (**ICLR2022**) [[paper](https://openreview.net/pdf?id=metRpM4Zrcb)]
- Continual Learning with Recursive Gradient Optimization (**ICLR2022**) [[paper](https://openreview.net/pdf?id=7YDLgf9_zgm)]
- TRGP: Trust Region Gradient Projection for Continual Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=iEvAf8i6JjO)]
- Looking Back on Learned Experiences For Class/task Incremental Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=RxplU3vmBx)]
- Continual Normalization: Rethinking Batch Normalization for Online Continual Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=vwLLQ-HwqhZ)]
- Model Zoo: A Growing Brain That Learns Continually (**ICLR2022**) [[paper](https://openreview.net/pdf?id=WfvgGBcgbE7)]
- Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting (**ICLR2022**) [[paper](https://openreview.net/pdf?id=tFgdrQbbaa)]
- Memory Replay with Data Compression for Continual Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=a7H7OucbWaU)]
- Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System (**ICLR2022**) [[paper](https://openreview.net/pdf?id=uxxFrDwrE7Y)]
- Online Coreset Selection for Rehearsal-based Continual Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=f9D-5WNG4Nv)]
- Pretrained Language Model in Continual Learning: A Comparative Study (**ICLR2022**) [[paper](https://openreview.net/pdf?id=figzpGMrdD)]
- Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference (**ICLR2022**) [[paper](https://openreview.net/pdf?id=nrGGfMbY_qK)]
- New Insights on Reducing Abrupt Representation Change in Online Continual Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=N8MaByOzUfb)]
- Towards Continual Knowledge Learning of Language Models  (**ICLR2022**) [[paper](https://openreview.net/pdf?id=vfsRB5MImo9)]
- CLEVA-Compass: A Continual Learning Evaluation Assessment Compass to Promote Research Transparency and Comparability  (**ICLR2022**) [[paper](https://openreview.net/pdf?id=rHMaBYbkkRJ)]
- CoMPS: Continual Meta Policy Search (**ICLR2022**) [[paper](https://openreview.net/pdf?id=PVJ6j87gOHz)]
- Information-theoretic Online Memory Selection for Continual Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=IpctgL7khPp)]
- Subspace Regularizers for Few-Shot Class Incremental Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=boJy41J-tnQ)]
- LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5 (**ICLR2022**) [[paper](https://openreview.net/pdf?id=HCRVf71PMF)]
- Effect of scale on catastrophic forgetting in neural networks (**ICLR2022**) [[paper]( https://openreview.net/pdf?id=GhVS8_yPeEa)]
- Dataset Knowledge Transfer for Class-Incremental Learning without Memory (**WACV2022**) [[paper](https://arxiv.org/pdf/2110.08421.pdf)]
- Knowledge Capture and Replay for Continual Learning (**WACV2022**) [[paper](https://openaccess.thecvf.com/content/WACV2022/papers/Gopalakrishnan_Knowledge_Capture_and_Replay_for_Continual_Learning_WACV_2022_paper.pdf)]
- Online Continual Learning via Candidates Voting (**WACV2022**) [[paper](https://openaccess.thecvf.com/content/WACV2022/papers/He_Online_Continual_Learning_via_Candidates_Voting_WACV_2022_paper.pdf)]

### 2021

- Incremental Object Detection via Meta-Learning (**TPAMI 2021**) [[paper](https://arxiv.org/abs/2003.08798)] [[code](https://github.com/JosephKJ/iOD)]
- Triple-Memory Networks: A Brain-Inspired Method for Continual Learning (**TNNLS 2021**) [[paper](https://ieeexplore.ieee.org/document/9540230)]
- Memory efficient class-incremental learning for image classification (**TNNLS 2021**) [[paper](https://ieeexplore.ieee.org/abstract/document/9422177)]
- Class-Incremental Learning via Dual Augmentation (**NeurIPS2021**) [[paper](https://papers.nips.cc/paper/2021/file/77ee3bc58ce560b86c2b59363281e914-Paper.pdf)]
- SSUL: Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning (**NeurIPS2021**) [[paper](https://proceedings.neurips.cc/paper/2021/file/5a9542c773018268fc6271f7afeea969-Paper.pdf)]
- RMM: Reinforced Memory Management for Class-Incremental Learning (**NeurIPS2021**) [[paper](https://proceedings.neurips.cc/paper/2021/hash/1cbcaa5abbb6b70f378a3a03d0c26386-Abstract.html)]
- Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima (**NeurIPS2021**) [[paper](https://openreview.net/forum?id=ALvt7nXa2q)]
- Lifelong Domain Adaptation via Consolidated Internal Distribution (**NeurIPS2021**) [[paper](https://openreview.net/forum?id=lpW-UP8VKcg)]
- AFEC: Active Forgetting of Negative Transfer in Continual Learning (**NeurIPS2021**) [[paper](https://openreview.net/pdf/72a18fad6fce88ef0286e9c7582229cf1c8d9f93.pdf)]
- Natural continual learning: success is a journey, not (just) a destination (**NeurIPS2021**) [[paper](https://openreview.net/forum?id=W9250bXDgpK)]
- Gradient-based Editing of Memory Examples for Online Task-free Continual Learning (**NeurIPS2021**) [[paper](https://papers.nips.cc/paper/2021/hash/f45a1078feb35de77d26b3f7a52ef502-Abstract.html)]
- Optimizing Reusable Knowledge for Continual Learning via Metalearning (**NeurIPS2021**) [[paper](https://openreview.net/forum?id=hHTctAv9Lvh)]
- Formalizing the Generalization-Forgetting Trade-off in Continual Learning (**NeurIPS2021**) [[paper](https://openreview.net/forum?id=u1XV9BPAB9)]
- Learning where to learn: Gradient sparsity in meta and continual learning (**NeurIPS2021**) [[paper](https://arxiv.org/abs/2110.14402)]
- Flattening Sharpness for Dynamic Gradient Projection Memory Benefits Continual Learning (**NeurIPS2021**) [[paper](https://openreview.net/forum?id=q1eCa1kMfDd)]
- Posterior Meta-Replay for Continual Learning (**NeurIPS2021**) [[paper](https://arxiv.org/abs/2103.01133)]
- Continual Auxiliary Task Learning (**NeurIPS2021**) [[paper](https://openreview.net/forum?id=EpL9IFAMa3)]
- Mitigating Forgetting in Online Continual Learning with Neuron Calibration (**NeurIPS2021**) [[paper](https://openreview.net/pdf/cc3ebd7a4834a4551e0b1f825969f9f51fd06415.pdf)]
- BNS: Building Network Structures Dynamically for Continual Learning (**NeurIPS2021**) [[paper](https://papers.nips.cc/paper/2021/hash/ac64504cc249b070772848642cffe6ff-Abstract.html)]
- DualNet: Continual Learning, Fast and Slow (**NeurIPS2021**) [[paper](https://openreview.net/pdf?id=eQ7Kh-QeWnO)]
- BooVAE: Boosting Approach for Continual Learning of VAE (**NeurIPS2021**) [[paper](https://papers.nips.cc/paper/2021/hash/952285b9b7e7a1be5aa7849f32ffff05-Abstract.html)]
- Generative vs. Discriminative: Rethinking The Meta-Continual Learning (**NeurIPS2021**) [[paper](https://papers.nips.cc/paper/2021/hash/b4e267d84075f66ebd967d95331fcc03-Abstract.html)]
- Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning (**NeurIPS2021**) [[paper](https://papers.nips.cc/paper/2021/hash/bcd0049c35799cdf57d06eaf2eb3cff6-Abstract.html)]
- Bridging Non Co-occurrence with Unlabeled In-the-wild Data for Incremental Object Detection (**NeurIPS, 2021**) [[paper](https://papers.nips.cc/paper/2021/file/ffc58105bf6f8a91aba0fa2d99e6f106-Paper.pdf)] [[code](https://github.com/dongnana777/Bridging-Non-Co-occurrence)]
- SS-IL: Separated Softmax for Incremental Learning (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Ahn_SS-IL_Separated_Softmax_for_Incremental_Learning_ICCV_2021_paper.pdf)]
- Striking a Balance between Stability and Plasticity for Class-Incremental Learning (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_Striking_a_Balance_Between_Stability_and_Plasticity_for_Class-Incremental_Learning_ICCV_2021_paper.pdf)]
- Synthesized Feature based Few-Shot Class-Incremental Learning on a Mixture of Subspaces (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Cheraghian_Synthesized_Feature_Based_Few-Shot_Class-Incremental_Learning_on_a_Mixture_of_ICCV_2021_paper.pdf)]
- Class-Incremental Learning for Action Recognition in Videos (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Park_Class-Incremental_Learning_for_Action_Recognition_in_Videos_ICCV_2021_paper.pdf)]
- Continual Prototype Evolution:Learning Online from Non-Stationary Data Streams (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/De_Lange_Continual_Prototype_Evolution_Learning_Online_From_Non-Stationary_Data_Streams_ICCV_2021_paper.pdf)]
- Rehearsal Revealed: The Limits and Merits of Revisiting Samples in Continual Learning (**ICCV, 2021**) [[paper](https://arxiv.org/abs/2104.07446)]
- Co2L: Contrastive Continual Learning (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.pdf)]
- Wanderlust: Online Continual Object Detection in the Real World (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Wanderlust_Online_Continual_Object_Detection_in_the_Real_World_ICCV_2021_paper.pdf)]
- Continual Learning on Noisy Data Streams via Self-Purified Replay (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Continual_Learning_on_Noisy_Data_Streams_via_Self-Purified_Replay_ICCV_2021_paper.pdf)]
- Else-Net: Elastic Semantic Network for Continual Action Recognition from Skeleton Data (**ICCV, 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Else-Net_Elastic_Semantic_Network_for_Continual_Action_Recognition_From_Skeleton_ICCV_2021_paper.pdf)]
- Detection and Continual Learning of Novel Face Presentation Attacks (**ICCV, 2021**) [[paper](https://arxiv.org/pdf/2108.12081.pdf)]
- Online Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data (**ICCV, 2021**) [[paper](https://arxiv.org/abs/2108.09020)]
- Continual Learning for Image-Based Camera Localization (**ICCV, 2021**) [[paper](https://arxiv.org/abs/2108.09112)]
- Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting (**ICCV, 2021**) [[paper](https://arxiv.org/abs/2108.08165)]
- Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning (**ICCV, 2021**) [[paper](https://arxiv.org/abs/2106.09701)]
- RECALL: Replay-based Continual Learning in Semantic Segmentation (**ICCV, 2021**) [[paper](https://arxiv.org/pdf/2108.03673.pdf)]
- Few-Shot and Continual Learning with Attentive Independent Mechanisms (**ICCV, 2021**) [[paper](https://arxiv.org/abs/2107.14053)]
- Learning with Selective Forgetting (**IJCAI, 2021**) [[paper](https://www.ijcai.org/proceedings/2021/0137.pdf)]
- Continuous Coordination As a Realistic Scenario for Lifelong Learning (**ICML, 2021**) [[paper](https://arxiv.org/pdf/2103.03216.pdf)]
- Kernel Continual Learning (**ICML, 2021**) [[paper](https://proceedings.mlr.press/v139/derakhshani21a.html)]
- Variational Auto-Regressive Gaussian Processes for Continual Learning (**ICML, 2021**) [[paper](https://proceedings.mlr.press/v139/kapoor21b.html)]
- Bayesian Structural Adaptation for Continual Learning (**ICML, 2021**) [[paper](https://proceedings.mlr.press/v139/kumar21a.html)]
- Continual Learning in the Teacher-Student Setup: Impact of Task Similarity (**ICML, 2021**) [[paper](https://proceedings.mlr.press/v139/lee21e.html)]
- Continuous Coordination As a Realistic Scenario for Lifelong Learning (**ICML, 2021**) [[paper](https://proceedings.mlr.press/v139/nekoei21a.html)]
- Federated Continual Learning with Weighted Inter-client Transfer (**ICML, 2021**) [[paper](http://proceedings.mlr.press/v139/yoon21b/yoon21b.pdf)]
- Adapting BERT for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks (**NAACL, 2021**) [[paper](https://www.aclweb.org/anthology/2021.naacl-main.378.pdf)]
- Continual Learning for Text Classification with Information Disentanglement Based Regularization (**NAACL, 2021**) [[paper](https://www.aclweb.org/anthology/2021.naacl-main.218.pdf)]
- CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks (**EMNLP, 2021**) [[paper](https://aclanthology.org/2021.emnlp-main.550/)][[code](https://github.com/ZixuanKe/PyContinual)]
- Co-Transport for Class-Incremental Learning (**ACM MM, 2021**) [[paper](https://arxiv.org/pdf/2107.12654.pdf)]
- Towards Open World Object Detection (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Joseph_Towards_Open_World_Object_Detection_CVPR_2021_paper.pdf)] [[code](https://github.com/JosephKJ/OWOD)] [[video](https://www.youtube.com/watch?v=aB2ZFAR-OZg)]
- Prototype Augmentation and Self-Supervision for Incremental Learning (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Prototype_Augmentation_and_Self-Supervision_for_Incremental_Learning_CVPR_2021_paper.pdf)] [[code](https://github.com/Impression2805/CVPR21_PASS)]
- ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_ORDisCo_Effective_and_Efficient_Usage_of_Incremental_Unlabeled_Data_for_CVPR_2021_paper.pdf)]
- Incremental Learning via Rate Reduction (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Incremental_Learning_via_Rate_Reduction_CVPR_2021_paper.pdf)]
- IIRC: Incremental Implicitly-Refined Classification (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Abdelsalam_IIRC_Incremental_Implicitly-Refined_Classification_CVPR_2021_paper.pdf)]
- Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Volpi_Continual_Adaptation_of_Visual_Representations_via_Domain_Randomization_and_Meta-Learning_CVPR_2021_paper.pdf)]
- Image De-raining via Continual Learning (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Image_De-Raining_via_Continual_Learning_CVPR_2021_paper.pdf)]
- Continual Learning via Bit-Level Information Preserving (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Continual_Learning_via_Bit-Level_Information_Preserving_CVPR_2021_paper.pdf)]
- Hyper-LifelongGAN: Scalable Lifelong Learning for Image Conditioned Generation (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhai_Hyper-LifelongGAN_Scalable_Lifelong_Learning_for_Image_Conditioned_Generation_CVPR_2021_paper.pdf)]
- Lifelong Person Re-Identification via Adaptive Knowledge Accumulation (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Pu_Lifelong_Person_Re-Identification_via_Adaptive_Knowledge_Accumulation_CVPR_2021_paper.pdf)]
- Distilling Causal Effect of Data in Class-Incremental Learning (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.01737)]
- Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning (**CVPR, 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Self-Promoted_Prototype_Refinement_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf)]
- Layerwise Optimization by Gradient Decomposition for Continual Learning (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2105.07561)]
- Adaptive Aggregation Networks for Class-Incremental Learning (**CVPR, 2021**) [[paper](https://arxiv.org/pdf/2010.05063.pdf)]
- Incremental Few-Shot Instance Segmentation (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2105.05312)]
- Efficient Feature Transformations for Discriminative and Generative Continual Learning (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.13558)]
- On Learning the Geodesic Path for Incremental Learning (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2104.08572)]
- Few-Shot Incremental Learning with Continually Evolved Classifiers (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2104.03047)]
- Rectification-based Knowledge Retention for Continual Learning (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.16597)]
- DER: Dynamically Expandable Representation for Class Incremental Learning (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.16788)]
- Rainbow Memory: Continual Learning with a Memory of Diverse Samples (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.17230)]
- Training Networks in Null Space of Feature Covariance for Continual Learning
 (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.07113)]
- Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning
 (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.04059)]
- PLOP: Learning without Forgetting for Continual Semantic Segmentation
 (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2011.11390)]
- Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations
 (**CVPR, 2021**) [[paper](https://arxiv.org/abs/2103.06342)]
- Online Class-Incremental Continual Learning with Adversarial Shapley Value(**AAAI, 2021**) [[paper](https://arxiv.org/abs/2009.00093)] [[code](https://github.com/RaptorMai/online-continual-learning)]
- Lifelong and Continual Learning Dialogue Systems: Learning during Conversation(**AAAI, 2021**)  [[paper](https://www.cs.uic.edu/~liub/publications/LINC_paper_AAAI_2021_camera_ready.pdf)]
- Continual learning for named entity recognition(**AAAI, 2021**) [[paper](https://www.amazon.science/publications/continual-learning-for-named-entity-recognition)]
- Using Hindsight to Anchor Past Knowledge in Continual Learning(**AAAI, 2021**) [[paper](https://arxiv.org/abs/2002.08165)]
- Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network(**AAAI, 2021**) [[paper](https://arxiv.org/abs/2107.01349)] [[code](https://github.com/bigdata-inha/Split-and-Bridge)]
- Curriculum-Meta Learning for Order-Robust Continual Relation Extraction(**AAAI, 2021**) [[paper](https://arxiv.org/abs/2101.01926)]
- Continual Learning by Using Information of Each Class Holistically(**AAAI, 2021**) [[paper](https://www.cs.uic.edu/~liub/publications/AAAI2021_PCL.pdf)]
- Gradient Regularized Contrastive Learning for Continual Domain Adaptation(**AAAI, 2021**) [[paper](https://arxiv.org/abs/2007.12942)]
- Unsupervised Model Adaptation for Continual Semantic Segmentation(**AAAI, 2021**) [[paper](https://arxiv.org/abs/2009.12518)]
- A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation(**AAAI, 2021**) [[paper](https://www.aaai.org/AAAI21Papers/AAAI-2989.ZhengE.pdf)]
- Do Not Forget to Attend to Uncertainty While Mitigating Catastrophic Forgetting(**WACV, 2021**) [[paper](https://openaccess.thecvf.com/content/WACV2021/html/Kurmi_Do_Not_Forget_to_Attend_to_Uncertainty_While_Mitigating_Catastrophic_WACV_2021_paper.html)]

### 2020

- Rethinking Experience Replay: a Bag of Tricks for Continual Learning(**ICPR, 2020**) [[paper](https://arxiv.org/abs/2010.05595)] [[code](https://github.com/hastings24/rethinking_er)]
- Continual Learning for Natural Language Generation in Task-oriented Dialog Systems(**EMNLP, 2020**) [[paper](https://arxiv.org/abs/2010.00910)]
- Distill and Replay for Continual Language Learning(**COLING, 2020**) [[paper](https://www.aclweb.org/anthology/2020.coling-main.318.pdf)]
- Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks (**NeurIPS2020**) [[paper](https://proceedings.neurips.cc/paper/2020/file/d7488039246a405baf6a7cbc3613a56f-Paper.pdf)] [[code](https://github.com/ZixuanKe/CAT)]
- Meta-Consolidation for Continual Learning (**NeurIPS2020**) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
- Understanding the Role of Training Regimes in Continual Learning (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2006.06958.pdf)]
- Continual Learning with Node-Importance based Adaptive Group Sparse Regularization (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2003.13726.pdf)]
- Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2003.05856.pdf)]
- Coresets via Bilevel Optimization for Continual Learning and Streaming (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2006.03875.pdf)]
- RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2007.06271.pdf)]
- Continual Deep Learning by Functional Regularisation of Memorable Past (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2004.14070.pdf)]
- Dark Experience for General Continual Learning: a Strong, Simple Baseline (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2004.07211.pdf)]  [[code](https://github.com/aimagelab/mammoth)]
- GAN Memory with No Forgetting (**NeurIPS2020**) [[paper](https://arxiv.org/pdf/2006.07543.pdf)]
- Calibrating CNNs for Lifelong Learning (**NeurIPS2020**) [[paper](http://people.ee.duke.edu/~lcarin/Final_Calibration_Incremental_Learning_NeurIPS_2020.pdf)]
- Mitigating Forgetting in Online Continual Learning
via Instance-Aware Parameterization (**NeurIPS2020**) [[paper](https://papers.nips.cc/paper/2020/file/ca4b5656b7e193e6bb9064c672ac8dce-Paper.pdf)]
- ADER: Adaptively Distilled Exemplar Replay Towards Continual Learning for Session-based Recommendation(**RecSys, 2020**) [[paper](https://arxiv.org/abs/2007.12000)]
- Initial Classifier Weights Replay for Memoryless Class Incremental Learning (**BMVC2020**) [[paper](https://arxiv.org/pdf/2008.13710.pdf)]
- Adversarial Continual Learning (**ECCV2020**) [[paper](https://arxiv.org/abs/2003.09553)]  [[code](https://github.com/facebookresearch/Adversarial-Continual-Learning)]
- REMIND Your Neural Network to Prevent Catastrophic Forgetting (**ECCV2020**) [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530460.pdf)]  [[code](https://github.com/tyler-hayes/REMIND)]
- Incremental Meta-Learning via Indirect Discriminant Alignment (**ECCV2020**) [[paper](https://arxiv.org/abs/2002.04162)]
- Memory-Efficient Incremental Learning Through Feature Adaptation (**ECCV2020**) [[paper](https://arxiv.org/abs/2004.00713)]
- PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning (**ECCV2020**) [[paper](https://arxiv.org/abs/2004.13513)] [[code](https://github.com/arthurdouillard/incremental_learning.pytorch)]
- Reparameterizing Convolutions for Incremental Multi-Task Learning Without Task Interference (**ECCV2020**) [[paper](https://arxiv.org/abs/2007.12540)]
- Learning latent representions across multiple data domains using Lifelong VAEGAN (**ECCV2020**) [[paper](https://arxiv.org/abs/2007.10221)]
- Online Continual Learning under Extreme Memory Constraints    (**ECCV2020**) [[paper](https://arxiv.org/abs/2008.01510)]
- Class-Incremental Domain Adaptation (**ECCV2020**) [[paper](https://arxiv.org/abs/2008.01389)]
- More Classifiers, Less Forgetting: A Generic Multi-classifier Paradigm for Incremental Learning (**ECCV2020**) [[paper](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710698.pdf)]
- Piggyback GAN: Efficient Lifelong Learning for Image Conditioned Generation (**ECCV2020**) [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660392.pdf)]
- GDumb: A Simple Approach that Questions Our Progress in Continual Learning     (**ECCV2020**) [[paper](http://www.robots.ox.ac.uk/~tvg/publications/2020/gdumb.pdf)]
- Imbalanced Continual Learning with Partitioning Reservoir Sampling     (**ECCV2020**) [[paper](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123580409.pdf)]
- Topology-Preserving Class-Incremental Learning (**ECCV2020**) [[paper](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123640256.pdf)]
- GraphSAIL: Graph Structure Aware Incremental Learning for Recommender Systems (**CIKM2020**) [[paper](https://arxiv.org/abs/2008.13517)]
- OvA-INN: Continual Learning with Invertible Neural Networks (**IJCNN2020**) [[paper](https://arxiv.org/abs/2006.13772)]
- XtarNet: Learning to Extract Task-Adaptive Representation
for Incremental Few-Shot Learning (**ICLM2020**) [[paper](https://arxiv.org/pdf/2003.08561.pdf)]
- Optimal Continual Learning has Perfect Memory and is NP-HARD (**ICML2020**) [[paper](https://arxiv.org/pdf/2006.05188.pdf)]
- Neural Topic Modeling with Continual Lifelong Learning (**ICML2020**) [[paper](https://arxiv.org/pdf/2006.10909.pdf)]
- Continual Learning with Knowledge Transfer for Sentiment Classification (**ECML-PKDD2020**) [[paper](https://www.cs.uic.edu/~liub/publications/ECML-PKDD-2020.pdf)] [[code](https://github.com/ZixuanKe/LifelongSentClass)]
- Semantic Drift Compensation for Class-Incremental Learning (**CVPR2020**) [[paper](https://arxiv.org/pdf/2004.00440.pdf)] [[code](https://github.com/yulu0724/SDC-IL)]
- Few-Shot Class-Incremental Learning (**CVPR2020**) [[paper](https://arxiv.org/pdf/2004.10956.pdf)]
- Modeling the Background for Incremental Learning in Semantic Segmentation (**CVPR2020**) [[paper](https://arxiv.org/pdf/2002.00718.pdf)]
- Incremental Few-Shot Object Detection (**CVPR2020**) [[paper](https://arxiv.org/pdf/2003.04668.pdf)]
- Incremental Learning In Online Scenario (**CVPR2020**) [[paper](https://arxiv.org/pdf/2003.13191.pdf)]
- Maintaining Discrimination and Fairness in Class Incremental Learning (**CVPR2020**) [[paper](https://arxiv.org/pdf/1911.07053.pdf)]
- Conditional Channel Gated Networks for Task-Aware Continual Learning (**CVPR2020**) [[paper](https://arxiv.org/pdf/2004.00070.pdf)]
- Continual Learning with Extended Kronecker-factored Approximate Curvature
 (**CVPR2020**) [[paper](https://arxiv.org/abs/2004.07507)]
- iTAML : An Incremental Task-Agnostic Meta-learning Approach (**CVPR2020**) [[paper](https://arxiv.org/pdf/2003.11652.pdf)] [[code](https://github.com/brjathu/iTAML)]
- Mnemonics Training: Multi-Class Incremental Learning without Forgetting (**CVPR2020**) [[paper](https://arxiv.org/pdf/2002.10211.pdf)] [[code](https://github.com/yaoyao-liu/mnemonics)]
- ScaIL: Classifier Weights Scaling for Class Incremental Learning (**WACV2020**) [[paper](https://arxiv.org/abs/2001.05755)]
- Accepted papers(**ICLR2020**) [[paper](https://docs.google.com/presentation/d/17s5Y8N9dypH-59tuwKaCp80NYBxTmtT6V-zOFlsH-SA/edit?usp=sharing)]
- Brain-inspired replay for continual learning with artificial neural networks (**Natrue Communications 2020**) [[paper](https://www.nature.com/articles/s41467-020-17866-2)] [[code](https://github.com/GMvandeVen/brain-inspired-replay)]
- Learning to Continually Learn (**ECAI 2020**) [[paper](https://arxiv.org/abs/2002.09571)] [[code](https://github.com/uvm-neurobotics-lab/ANML)]

### 2019

- Compacting, Picking and Growing for Unforgetting Continual Learning (**NeurIPS2019**)[[paper](https://papers.nips.cc/paper/9518-compacting-picking-and-growing-for-unforgetting-continual-learning.pdf)][[code](https://github.com/ivclab/CPG)]
- Increasingly Packing Multiple Facial-Informatics Modules in A Unified Deep-Learning Model via Lifelong Learning (**ICMR2019**) [[paper](https://dl.acm.org/doi/10.1145/3323873.3325053)][[code](https://github.com/ivclab/PAE)]
- Towards Training Recurrent Neural Networks for Lifelong Learning (**Neural Computation 2019**) [[paper](https://arxiv.org/pdf/1811.07017.pdf)]
- Complementary Learning for Overcoming Catastrophic Forgetting Using Experience Replay  (**IJCAI2019**) [[paper]](https://www.ijcai.org/Proceedings/2019/0463.pdf)
- IL2M: Class Incremental Learning With Dual Memory
 (**ICCV2019**) [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Belouadah_IL2M_Class_Incremental_Learning_With_Dual_Memory_ICCV_2019_paper.pdf)]
- Incremental Learning Using Conditional Adversarial Networks
 (**ICCV2019**) [[paper](http://openaccess.thecvf.com/content_ICCV_2019/html/Xiang_Incremental_Learning_Using_Conditional_Adversarial_Networks_ICCV_2019_paper.html)]
- Adaptive Deep Models for Incremental Learning: Considering Capacity Scalability and Sustainability (**KDD2019**) [[paper](http://www.lamda.nju.edu.cn/yangy/KDD19.pdf)]
- Random Path Selection for Incremental Learning (**NeurIPS2019**) [[paper](https://arxiv.org/pdf/1906.01120.pdf)]
- Online Continual Learning with Maximal Interfered Retrieval (**NeurIPS2019**) [[paper](http://papers.neurips.cc/paper/9357-online-continual-learning-with-maximal-interfered-retrieval)]
- Meta-Learning Representations for Continual Learning (**NeurIPS2019**) [[paper](http://papers.nips.cc/paper/8458-meta-learning-representations-for-continual-learning.pdf)] [[code](https://github.com/Khurramjaved96/mrcl)]
- Overcoming Catastrophic Forgetting with Unlabeled Data in the Wild (**ICCV2019**) [[paper](https://arxiv.org/pdf/1903.12648.pdf)]
- Continual Learning by Asymmetric Loss Approximation
with Single-Side Overestimation (**ICCV2019**) [[paper](https://arxiv.org/pdf/1908.02984.pdf)]
- Lifelong GAN: Continual Learning for Conditional Image Generation (**ICCV2019**) [[paper](https://arxiv.org/pdf/1907.10107.pdf)]
- Continual learning of context-dependent processing in neural networks (**Nature Machine Intelligence 2019**) [[paper](https://rdcu.be/bOaa3)] [[code](https://github.com/beijixiong3510/OWM)]
- Large Scale Incremental Learning (**CVPR2019**) [[paper](https://arxiv.org/abs/1905.13260)] [[code](https://github.com/wuyuebupt/LargeScaleIncrementalLearning)]
- Learning a Unified Classifier Incrementally via Rebalancing (**CVPR2019**) [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Hou_Learning_a_Unified_Classifier_Incrementally_via_Rebalancing_CVPR_2019_paper.pdf)] [[code](https://github.com/hshustc/CVPR19_Incremental_Learning)]
- Learning Without Memorizing (**CVPR2019**) [[paper](https://arxiv.org/pdf/1811.08051.pdf)]
- Learning to Remember: A Synaptic Plasticity Driven Framework for Continual Learning (**CVPR2019**) [[paper](https://arxiv.org/abs/1904.03137)]
- Task-Free Continual Learning (**CVPR2019**) [[paper](https://arxiv.org/pdf/1812.03596.pdf)]
- Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting (**ICML2019**) [[paper](https://arxiv.org/abs/1904.00310)]
- Efficient Lifelong Learning with A-GEM (**ICLR2019**) [[paper](https://openreview.net/forum?id=Hkf2_sC5FX)] [[code](https://github.com/facebookresearch/agem)]
- Learning to Learn without Forgetting By Maximizing Transfer and Minimizing Interference (**ICLR2019**) [[paper](https://openreview.net/forum?id=B1gTShAct7)] [[code](https://github.com/mattriemer/mer)]
- Overcoming Catastrophic Forgetting via Model Adaptation (**ICLR2019**) [[paper](https://openreview.net/forum?id=ryGvcoA5YX)]
- A comprehensive, application-oriented study of catastrophic forgetting in DNNs (**ICLR2019**) [[paper](https://openreview.net/forum?id=BkloRs0qK7)]

### 2018

- Memory Replay GANs: learning to generate images from new categories without forgetting
 (**NIPS2018**) [[paper](https://arxiv.org/abs/1809.02058)] [[code](https://github.com/WuChenshen/MeRGAN)]
- Reinforced Continual Learning (**NIPS2018**) [[paper](http://papers.nips.cc/paper/7369-reinforced-continual-learning.pdf)] [[code](https://github.com/xujinfan/Reinforced-Continual-Learning)]
- Online Structured Laplace Approximations for Overcoming Catastrophic Forgetting (**NIPS2018**) [[paper](http://papers.nips.cc/paper/7631-online-structured-laplace-approximations-for-overcoming-catastrophic-forgetting.pdf)]
- Rotate your Networks: Better Weight Consolidation and Less Catastrophic Forgetting (R-EWC) (**ICPR2018**) [[paper](https://arxiv.org/abs/1802.02950)] [[code](https://github.com/xialeiliu/RotateNetworks)]
- Exemplar-Supported Generative Reproduction for Class Incremental Learning  (**BMVC2018**) [[paper](http://bmvc2018.org/contents/papers/0325.pdf)] [[code](https://github.com/TonyPod/ESGR)]
- End-to-End Incremental Learning (**ECCV2018**) [[paper](https://arxiv.org/abs/1807.09536)][[code](https://github.com/fmcp/EndToEndIncrementalLearning)]
- Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence (**ECCV2018**)[[paper](http://arxiv-export-lb.library.cornell.edu/abs/1801.10112)]
- Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights (**ECCV2018**) [[paper](https://arxiv.org/abs/1801.06519)] [[code](https://github.com/arunmallya/piggyback)]
- Memory Aware Synapses: Learning what (not) to forget (**ECCV2018**) [[paper](https://arxiv.org/abs/1711.09601)] [[code](https://github.com/rahafaljundi/MAS-Memory-Aware-Synapses)]
- Lifelong Learning via Progressive Distillation and Retrospection (**ECCV2018**) [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Saihui_Hou_Progressive_Lifelong_Learning_ECCV_2018_paper.pdf)]
- PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning (**CVPR2018**) [[paper](https://arxiv.org/abs/1711.05769)] [[code](https://github.com/arunmallya/packnet)]
- Overcoming Catastrophic Forgetting with Hard Attention to the Task (**ICML2018**) [[paper](http://proceedings.mlr.press/v80/serra18a.html)] [[code](https://github.com/joansj/hat)]
- Lifelong Learning with Dynamically Expandable Networks (**ICLR2018**) [[paper](https://openreview.net/forum?id=Sk7KsfW0-)]
- FearNet: Brain-Inspired Model for Incremental Learning (**ICLR2018**) [[paper](https://openreview.net/forum?id=SJ1Xmf-Rb)]

### 2017

- Incremental Learning of Object Detectors Without Catastrophic Forgetting
 (**ICCV2017**) [[paper](http://openaccess.thecvf.com/content_iccv_2017/html/Shmelkov_Incremental_Learning_of_ICCV_2017_paper.html)]
- Overcoming catastrophic forgetting in neural networks (EWC) (**PNAS2017**) [[paper](https://arxiv.org/abs/1612.00796)] [[code](https://github.com/ariseff/overcoming-catastrophic)] [[code](https://github.com/stokesj/EWC)]
- Continual Learning Through Synaptic Intelligence (**ICML2017**) [[paper](http://proceedings.mlr.press/v70/zenke17a.html)] [[code](https://github.com/ganguli-lab/pathint)]
- Gradient Episodic Memory for Continual Learning (**NIPS2017**) [[paper](https://arxiv.org/abs/1706.08840)] [[code](https://github.com/facebookresearch/GradientEpisodicMemory)]
- iCaRL: Incremental Classifier and Representation Learning (**CVPR2017**) [[paper](https://arxiv.org/abs/1611.07725)] [[code](https://github.com/srebuffi/iCaRL)]
- Continual Learning with Deep Generative Replay (**NIPS2017**) [[paper](https://arxiv.org/abs/1705.08690)] [[code](https://github.com/kuc2477/pytorch-deep-generative-replay)]
- Overcoming Catastrophic Forgetting by Incremental Moment Matching (**NIPS2017**) [[paper](https://arxiv.org/abs/1703.08475)] [[code](https://github.com/btjhjeon/IMM_tensorflow)]
- Expert Gate: Lifelong Learning with a Network of Experts (**CVPR2017**) [[paper](https://arxiv.org/abs/1611.06194)]
- Encoder Based Lifelong Learning (**ICCV2017**) [[paper](https://arxiv.org/abs/1704.01920)]

### 2016

- Learning without forgetting (**ECCV2016**) [[paper](https://link.springer.com/chapter/10.1007/978-3-319-46493-0_37)] [[code](https://github.com/lizhitwo/LearningWithoutForgetting)]
